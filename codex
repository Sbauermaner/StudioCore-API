#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Codex helper CLI for StudioCore loader diagnostics and PR automation."""
from __future__ import annotations

import argparse
import contextlib
import glob
import importlib
import io
import json
import os
import re
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional, Sequence

# ============================
# Default subsystem expectations
# ============================
DEFAULT_SUBSYSTEMS = [
    "emotion",
    "tlp",
    "rhythm",
    "freq",
    "safety",
    "integrity",
    "vocals",
    "style",
    "tone",
]

EXPECTED_LOADER_ORDER = ("v6", "monolith", "fallback")


# ============================
# Utility functions
# ============================

def _resolve_target(pattern: str) -> List[str]:
    matches = sorted(glob.glob(pattern, recursive=True))
    return [str(Path(m)) for m in matches if os.path.exists(m)]


def _load_module(name: str):
    return importlib.import_module(name)


def _instantiate_core(module: Any):
    get_core = getattr(module, "get_core", None)
    if not callable(get_core):
        raise RuntimeError("studiocore.get_core() is not callable")
    return get_core()


def _run_git(args: Sequence[str], check: bool = True) -> subprocess.CompletedProcess:
    proc = subprocess.run(
        ["git", *args],
        capture_output=True,
        text=True,
        check=False,
    )
    if check and proc.returncode != 0:
        details = proc.stderr.strip() or proc.stdout.strip() or "unknown error"
        raise RuntimeError(
            f"git {' '.join(args)} failed with exit code {proc.returncode}: {details}"
        )
    return proc


def _get_default_remote() -> Optional[str]:
    remotes = _run_git(["remote"], check=False)
    for line in remotes.stdout.splitlines():
        name = line.strip()
        if name:
            return name
    return None


def _fast_forward_branch(branch: str, *, remote: str) -> Optional[str]:
    remote_ref = f"{remote}/{branch}"
    probe = _run_git(["rev-parse", "--verify", remote_ref], check=False)
    if probe.returncode != 0:
        return f"Remote ref '{remote_ref}' not found — fast-forward skipped."
    _run_git(["checkout", branch], check=True)
    ff_merge = _run_git(["merge", "--ff-only", remote_ref], check=True)
    return f"Fast-forwarded {branch} to {remote_ref}: {_format_git_output(ff_merge)}"


def _ensure_branch(branch: str, *, create: bool = False, start_point: Optional[str] = None) -> bool:
    """Ensure branch exists, or create it."""
    probe = _run_git(["rev-parse", "--verify", branch], check=False)
    if probe.returncode == 0:
        return False
    if not create:
        raise RuntimeError(f"Branch '{branch}' was not found in this repository")
    ref = start_point or "HEAD"
    _run_git(["branch", branch, ref], check=True)
    return True


def _ensure_clean_worktree() -> None:
    status = _run_git(["status", "--porcelain"], check=True)
    if status.stdout.strip():
        raise RuntimeError(
            "The working tree contains uncommitted changes. Commit or stash them before running Codex PR automation."
        )


def _format_git_output(proc: subprocess.CompletedProcess) -> str:
    msg = proc.stdout.strip() or proc.stderr.strip()
    return msg or "Already up to date."


def _deep_merge_dict(a: Dict[str, Any], b: Dict[str, Any]) -> Dict[str, Any]:
    merged = dict(a)
    for key, value in b.items():
        if key in merged and isinstance(merged[key], dict) and isinstance(value, dict):
            merged[key] = _deep_merge_dict(merged[key], value)
        else:
            merged[key] = value
    return merged


# ============================
# Loader file helper
# ============================
class LoaderFile:
    ORDER_PATTERN = re.compile(r"DEFAULT_LOADER_ORDER\s*=\s*\((?P<body>.*?)\)", re.S)

    def __init__(self, path: str):
        self.path = Path(path)
        self.source = self.path.read_text(encoding="utf-8")

    def detect_order(self) -> List[str]:
        match = self.ORDER_PATTERN.search(self.source)
        if not match:
            return []
        body = match.group("body")
        return re.findall(r"['\"]([^'\"]+)['\"]", body)

    def ensure_order(self, expected: Sequence[str]) -> bool:
        block = "DEFAULT_LOADER_ORDER = (\n" + "\n".join(f'    "{x}",' for x in expected) + "\n)"
        if self.ORDER_PATTERN.search(self.source):
            new_source = self.ORDER_PATTERN.sub(block, self.source, count=1)
        else:
            insert_at = self.source.find("STUDIOCORE_VERSION")
            insert_at = self.source.find("\n", insert_at) if insert_at != -1 else 0
            new_source = self.source[:insert_at] + "\n" + block + "\n" + self.source[insert_at:]
        changed = new_source != self.source
        if changed:
            self.source = new_source
        return changed

    def fix_duplicates(self, names: Sequence[str]) -> bool:
        seen = {name: 0 for name in names}
        changed = False
        new_lines = []
        for line in self.source.splitlines():
            stripped = line.strip()
            drop = False
            for name in names:
                if stripped.startswith(f"{name} ="):
                    seen[name] += 1
                    if seen[name] > 1:
                        drop = True
                        changed = True
                    break
            if not drop:
                new_lines.append(line)
        if changed:
            self.source = "\n".join(new_lines) + ("\n" if self.source.endswith("\n") else "")
        return changed

    def save(self):
        self.path.write_text(self.source, encoding="utf-8")


# ============================
# Diagnostics
# ============================

def diagnose(args: argparse.Namespace) -> int:
    if args.full:
        for flag in [
            "runtime", "check_init", "check_subsystems", "check_env",
            "check_loader", "check_monolith", "check_v6", "check_versions",
            "verify_fallback_chain", "fix_loader_order",
            "fix_version_duplicates", "ensure_v6_priority", "deep_merge",
        ]:
            setattr(args, flag, True)

    report = {
        "command": "diagnose",
        "targets": _resolve_target(args.target),
        "commit": args.commit,
        "runtime": {},
        "init": {},
        "subsystems": {},
        "env": {},
        "loader": {},
        "versions": {},
        "repairs": [],
    }
    failures = []

    module = None
    core = None

    # Runtime import
    if args.runtime or args.check_init or args.check_subsystems:
        try:
            module = _load_module("studiocore")
            report["runtime"] = {
                "module": getattr(module, "__file__", "?"),
                "STUDIOCORE_VERSION": getattr(module, "STUDIOCORE_VERSION", "?"),
                "MONOLITH_VERSION": getattr(module, "MONOLITH_VERSION", "?"),
            }
        except Exception as exc:
            failures.append(f"Runtime import failed: {exc}")
            report["runtime"] = {"error": str(exc)}

    if module and args.check_versions:
        versions = {
            "STUDIOCORE_VERSION": getattr(module, "STUDIOCORE_VERSION", "?"),
            "MONOLITH_VERSION": getattr(module, "MONOLITH_VERSION", "?"),
        }
        report["versions"] = versions
        for k, v in versions.items():
            if v in {None, "?", "unknown"}:
                failures.append(f"{k} is not set")

    # Initialize core
    if module and args.check_init:
        try:
            core = _instantiate_core(module)
            report["init"] = {
                "core_type": type(core).__name__,
                "is_fallback": getattr(core, "is_fallback", False),
            }
        except Exception as exc:
            failures.append(f"Core initialization failed: {exc}")
            report["init"] = {"error": str(exc)}

    # Check subsystems
    if core and args.check_subsystems:
        active = [name for name in DEFAULT_SUBSYSTEMS if hasattr(core, name)]
        missing = sorted(set(DEFAULT_SUBSYSTEMS) - set(active))
        report["subsystems"] = {"expected": DEFAULT_SUBSYSTEMS, "active": active, "missing": missing}
        if missing:
            failures.append("Missing subsystems: " + ", ".join(missing))

    # Loader file repair
    loader_file_reports = []
    for path in report["targets"]:
        if path.endswith(".py") and os.path.exists(path):
            lf = LoaderFile(path)
            f_report = {"path": path, "order": lf.detect_order()}
            loader_file_reports.append(f_report)

            changed = False
            actions = []

            if args.fix_loader_order and lf.ensure_order(EXPECTED_LOADER_ORDER):
                changed = True
                actions.append("fix_loader_order")

            if args.ensure_v6_priority and lf.ensure_order(EXPECTED_LOADER_ORDER):
                changed = True
                actions.append("ensure_v6_priority")

            if args.fix_version_duplicates and lf.fix_duplicates(["STUDIOCORE_VERSION", "MONOLITH_VERSION"]):
                changed = True
                actions.append("fix_version_duplicates")

            if changed:
                lf.save()

            if actions:
                report["repairs"].append({"path": path, "actions": actions})

    if loader_file_reports:
        report["loader"]["files"] = loader_file_reports

    # Env
    if args.check_env:
        report["env"] = {
            "STUDIOCORE_MONOLITH": os.getenv("STUDIOCORE_MONOLITH"),
            "STUDIOCORE_LOADER_ORDER": os.getenv("STUDIOCORE_LOADER_ORDER"),
        }

    # Runtime loader metadata
    if module and (args.check_loader or args.verify_fallback_chain):
        loader_graph = getattr(module, "LOADER_GRAPH", {})
        default_order = list(getattr(module, "DEFAULT_LOADER_ORDER", []))
        loader_status = getattr(module, "LOADER_STATUS", {})

        report["loader"]["runtime"] = {
            "default_order": default_order,
            "graph": {
                k: {
                    "available": bool(v.get("loader")),
                    "name": v.get("name"),
                    "version": v.get("version"),
                }
                for k, v in loader_graph.items()
            },
            "status": loader_status,
        }

        normalized = [x.lower() for x in default_order]
        if normalized[:3] != list(EXPECTED_LOADER_ORDER):
            failures.append("Loader order does not prioritize v6 → monolith → fallback")

    # Final
    print(json.dumps(report, indent=2, ensure_ascii=False))
    return 0 if not failures else 1


# ============================
# Full runtime-checks
# ============================

def runtime_checks(args: argparse.Namespace) -> int:
    diag_args = argparse.Namespace(
        full=True,
        runtime=True,
        check_init=True,
        check_subsystems=True,
        check_env=True,
        check_loader=True,
        check_monolith=True,
        check_v6=True,
        check_versions=True,
        verify_fallback_chain=True,
        fix_loader_order=True,
        fix_version_duplicates=True,
        ensure_v6_priority=True,
        deep_merge=True,
        target=args.target,
        commit=args.commit,
        func=diagnose,
    )

    buf = io.StringIO()
    with contextlib.redirect_stdout(buf):
        exit_code = diagnose(diag_args)

    output = buf.getvalue()
    print(output, end="")

    if args.output and args.output != "-":
        path = Path(args.output)
        path.parent.mkdir(parents=True, exist_ok=True)
        ts = datetime.now(timezone.utc).isoformat()
        header = f"=== Runtime Check @ {ts} ===\n"
        with path.open("a", encoding="utf-8") as f:
            f.write(header + output)
            if not output.endswith("\n"):
                f.write("\n")

    return exit_code


# ============================
# Pull-request automation
# ============================

def merge_pr(args: argparse.Namespace) -> int:
    source = args.source
    target = args.target
    summary = []

    try:
        if not args.allow_dirty:
            _ensure_clean_worktree()

        # Create branches if missing
        if _ensure_branch(
            source,
            create=args.create_missing,
            start_point=args.create_source_from or "HEAD",
        ):
            summary.append(f"Created missing branch '{source}'")

        if _ensure_branch(
            target,
            create=args.create_missing,
            start_point=args.create_target_from or "HEAD",
        ):
            summary.append(f"Created missing branch '{target}'")

        previous = (
            _run_git(["rev-parse", "--abbrev-ref", "HEAD"], check=True).stdout.strip()
        )

        remote_name = _get_default_remote()

        # Fetch updates
        if not args.skip_fetch:
            if remote_name:
                fetch = _run_git(["fetch", "--all"], check=True)
                summary.append(f"Fetched: {_format_git_output(fetch)}")
            else:
                summary.append("No remote — fetch skipped.")

        # Fast-forward local branches to their remotes so we merge the freshest refs
        if remote_name and not args.skip_fetch:
            for branch in (source, target):
                message = _fast_forward_branch(branch, remote=remote_name)
                if message:
                    summary.append(message)

        # Sync source with target
        _run_git(["checkout", source], check=True)
        sync = _run_git(["merge", target], check=True)
        summary.append(f"Synced {source} with {target}: {_format_git_output(sync)}")

        # Merge source → target
        _run_git(["checkout", target], check=True)
        cmd = ["merge"]
        if args.strategy == "ff-only":
            cmd.append("--ff-only")
        elif args.strategy == "no-ff":
            cmd.append("--no-ff")
        cmd.append(source)
        merge_exec = _run_git(cmd, check=True)
        summary.append(f"Merged {source} → {target}: {_format_git_output(merge_exec)}")

        # Restore previous branch
        if args.restore_branch and previous not in {source, target}:
            _run_git(["checkout", previous], check=True)
            summary.append(f"Restored branch: {previous}")

    except RuntimeError as exc:
        print(f"❌ {exc}")
        return 1

    print("Codex PR Summary:")
    for line in summary:
        print(" -", line)
    print(f"✅ Completed: {source} → {target}")
    return 0


# ============================
# CLI parser
# ============================

def build_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(prog="codex", description="StudioCore Codex utility")
    sub = parser.add_subparsers(dest="command", required=True)

    # ---- diagnose
    p = sub.add_parser("diagnose", help="Run diagnostics")
    p.add_argument("--full", action="store_true")
    p.add_argument("--runtime", action="store_true")
    p.add_argument("--check-init", action="store_true")
    p.add_argument("--check-subsystems", action="store_true")
    p.add_argument("--check-env", action="store_true")
    p.add_argument("--check-loader", action="store_true")
    p.add_argument("--check-monolith", action="store_true")
    p.add_argument("--check-v6", action="store_true")
    p.add_argument("--check-versions", action="store_true")
    p.add_argument("--verify-fallback-chain", action="store_true")
    p.add_argument("--fix-loader-order", action="store_true")
    p.add_argument("--fix-version-duplicates", action="store_true")
    p.add_argument("--ensure-v6-priority", action="store_true")
    p.add_argument("--deep-merge", action="store_true")
    p.add_argument("--target", default="studiocore/*")
    p.add_argument("--commit", default=None)
    p.set_defaults(func=diagnose)

    # ---- runtime-checks
    p2 = sub.add_parser("runtime-checks", help="Full diagnostic suite")
    p2.add_argument("--target", default="studiocore/*")
    p2.add_argument("--commit", default=None)
    p2.add_argument("--output", default="test_log.txt")
    p2.set_defaults(func=runtime_checks)

    # ---- merge-pr
    p3 = sub.add_parser("merge-pr", help="Sync + merge branches")
    p3.add_argument("source", help="Source branch")
    p3.add_argument("--target", default="main")
    p3.add_argument("--skip-fetch", action="store_true")
    p3.add_argument("--allow-dirty", action="store_true")
    p3.add_argument("--strategy", choices=["merge", "ff-only", "no-ff"], default="merge")
    p3.add_argument("--restore-branch", action="store_true")
    p3.add_argument("--create-missing", action="store_true")
    p3.add_argument("--create-source-from", default=None)
    p3.add_argument("--create-target-from", default=None)
    p3.set_defaults(func=merge_pr)

    return parser


def main(argv: List[str] | None = None) -> int:
    parser = build_parser()
    args = parser.parse_args(argv)
    return args.func(args)


if __name__ == "__main__":
    sys.exit(main())
