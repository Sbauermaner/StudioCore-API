Отчёт аудита StudioCore — директория studiocore/* (полное сканирование)
Дата: 2025-11-21 (UTC)

1) Реальный порядок пайплайна и пропуски шагов
- Фактический граф StudioCoreV6.analyze: инициализация всех движков → очистка текста/детект языка → translate → SectionParser + разбор команд → применение user overrides → вызов _backend_analyze → финальная сборка Compiler. Это подтверждает, что все дальнейшие метрики строятся поверх LegacyEmotionEngine/EmotionEngine, SectionParser и динамических подсказок, а также что любые сбои в предыдущих шагах «тянут» за собой всё последующее вычисление.【F:studiocore/core_v6.py†L95-L187】
- Внутри _backend_analyze сначала вызывается monolith LegacyCore, затем уже структура/эмоции/BPM/тональность/жанр. Даже если legacy_result содержит ошибку, дальнейшие шаги продолжают работать на частично пустых данных, флаг обрыва отсутствует. Это создаёт «застрявшие» шаги (BPM/жанр/тональность) без валидного источника и скрывает сбои базового ядра от внешних потребителей.【F:studiocore/core_v6.py†L263-L340】
- FusionEngineV64 и Suno prompt builder из adapter.py ни разу не инстанцируются и не вызываются из analyze/_backend_analyze: пайплайн завершает работу на compiler.generate_final_prompt/annotations без стадий fusion_summary и специализированного suno_prompt. В результате отсутствуют консолидированные BPM/тональность/жанр и целевой Suno prompt, заявленные в движках, что делает последовательность шагов неполной.【F:studiocore/fusion_engine_v64.py†L1-L129】【F:studiocore/adapter.py†L25-L120】

2) Проверка согласованности движков
- Вокальный слой модифицируется дважды: сначала apply_to_vocals в середине _backend_analyze, а затем _apply_vocal_fusion, что добавляет метаданные. Эти операции выполняются до передачи payload в override_engine.apply_once, поэтому повторное применение оверрайдов позже может переопределить уже записанные поля и разойтись с diagnostics, нарушая консистентность вокального движка относительно остальных модулей.【F:studiocore/core_v6.py†L430-L487】【F:studiocore/core_v6.py†L1464-L1488】
- Тональный слой вычисляет модальные сдвиги ToneSyncEngine и сохраняет их только в служебном поле _tone_dynamic; основная структура tonality_payload, отдаваемая наружу и использующаяся жанровым/частотным блоком, не содержит этих поправок. Итоговые ключ/модальность теряют эмоциональную модуляцию и расходятся с цветовым/частотным контуром, ломая обещанную синхронизацию «тон ↔ эмоция».【F:studiocore/core_v6.py†L560-L593】
- SectionParser напрямую записывает metadata в приватное поле TextStructureEngine._section_metadata и не защищает длину списка от расхождений с auto_section_split; при пустых секциях длины могут разойтись, и downstream (SectionIntelligence, annotation_engine) будет читать несовпадающие headers/sections. Это нарушает согласованность секционного парсера с аннотациями и жанровыми/вокальными подсказками, которые используют section_metadata.【F:studiocore/section_parser.py†L47-L75】

3) Логические ошибки, протечки состояния и сериализация
- TruthLovePainEngine.export_emotion_vector и RhythmDynamicsEmotionEngine.export_emotion_vector всегда возвращают нейтральный EmotionVector без учёта входного текста. Эти классы выступают как адаптеры для динамического режима, но фактически «протекают» класс-статус нейтрали в итоговые карты эмоций/ритма, обнуляя TLP-сигналы, которые затем используются тональным и частотным блоком. Это приводит к несоответствию типа/значения (ожидается текст-зависимый вектор).【F:studiocore/tlp_engine.py†L28-L39】【F:studiocore/rde_engine.py†L57-L68】
- EmotionEngine (legacy) использует класс-уровневые веса/поля (WEIGHTS и другие коллекции), которые модифицируются в процессе анализа и разделяются между экземплярами. Такое состояние не сериализуемо и переносит «память» между запросами, что создаёт залипание эмоций/весов и нарушает требование чистоты анализа для новых текстов.【F:studiocore/emotion_engine.py†L29-L135】
- SectionParser перезаписывает приватное поле _section_metadata вместо публичного API и не копирует объект TextStructureEngine. При повторных вызовах одного экземпляра SectionParser метаданные прошлых запросов могут быть переиспользованы (stale memory), если auto_section_split выдаст меньше секций, чем сохранено в поле, что создаёт неверные аннотации и неверные подсказки для downstream движков.【F:studiocore/section_parser.py†L47-L75】

4) Риски некорректного текстового анализа
- Отсутствие явной остановки при ошибках LegacyCore (см. п.1) даёт валидно выглядящие BPM/жанр/тональность даже при пустом legacy_result. Клиенты и Suno builder получают «успешный» ответ без данных, что приводит к неверным подсказкам и потенциально некорректным промптам.【F:studiocore/core_v6.py†L263-L340】
- Нейтральные TLP/RDE векторы (см. п.3) заставляют ToneSyncEngine и UniversalFrequencyEngine работать от усреднённых значений, обнуляя детекцию truth/love/pain и перекрашивая частотный профиль в «нейтральный». Это напрямую снижает точность частотного, тонального и вокального движков и может подменять реальные эмоциональные подсказки пользователя.【F:studiocore/tlp_engine.py†L28-L39】【F:studiocore/rde_engine.py†L57-L68】【F:studiocore/core_v6.py†L560-L599】
- Двойная мутация вокального слоя плюс незадействованные fusion/suno шаги означают, что итоговая Suno-аннотация и жанровый матрикс не проходят финальную нормализацию: build_suno_safe_annotations строит строки на уже «сырых» diagnostics без fusion_summary, поэтому текстовый анализ может выдавать неполные или противоречивые подсказки Suno (например, bpm/key из разных источников).【F:studiocore/suno_annotations.py†L90-L129】【F:studiocore/core_v6.py†L430-L487】【F:studiocore/fusion_engine_v64.py†L1-L129】

Отчёт фиксирует выявленные несоответствия; изменений кода не вносилось.

=== POST-FIX AUDIT (2025-11-21 14:25 UTC) ===
1) Runtime/import sanity
- StudioCoreV6 imported and instantiated without ImportError/TypeError; loader reported monolith_v4_3_1 availability.

2) Pytest regression
- Command: pytest tests
- Result: 48 passed, 0 failed, 0 skipped (duration ~0.6s).

3) TLP Engine / export_emotion_vector
- Positive text: EmotionVector(truth=0.0, love=1.0, pain=0.0, valence=1.0, arousal=0.333, weight=1.0)
- Painful text: EmotionVector(truth=0.0, love=0.0, pain=1.0, valence=-1.0, arousal=0.333, weight=0.0)
- Mixed text: EmotionVector(truth=0.333, love=0.333, pain=0.333, valence=0.0, arousal=0.333, weight=0.667)
- Valence/arousal respond to text; weight follows conscious_frequency (not forced to 1.0).

4) VocalEngine + ToneSync dynamic check
- VocalEngine.detect_voice_tone returned varied tones: positive=intense, painful=cold, mixed=balanced.
- ToneSyncEngine.detect_key + apply_emotion_modulation ran without exceptions; modulations differed by text (brighter_major vs darker_minor vs default).

5) FANF statelessness
- build_fanf_output produces fanf_text/sections/context strictly from inputs; second call with different text/sections/context returned its own values without residual data from first call.
- Note: analyze() returned None for normalized text/sections/context due to missing translation configuration, but build_fanf_output remained stateless.

6) Test runner path resolution
- run_inline_tests resolves tests directory via BASE_DIR join -> /workspace/StudioCore-API/tests (no "//tests" prefix). Simulated path exists.

Warnings/observations
- analyze() path requires translation configuration to populate normalized text/sections/context; fallback paths return None.
