# -*- coding: utf-8 -*-
"""
StudioCore v4.3.11 ‚Äî Monolith (v6 - Suno –ê–Ω–Ω–æ—Ç–∞—Ü–∏–∏)
- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ f-string (—Å—Ç—Ä–æ–∫–∞ 259)
- –í–Ω–µ–¥—Ä–µ–Ω–æ —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
- –í–Ω–µ–¥—Ä–µ–Ω–∞ Suno-–∞–Ω–Ω–æ—Ç–∞—Ü–∏—è –≤ 'annotate_text'
"""

from __future__ import annotations
import re
import json
from statistics import mean
from typing import Dict, Any, List, Tuple, Optional
import logging

# === 1. –ò–º–ø–æ—Ä—Ç —è–¥—Ä–∞ ===
# StudioCore Signature Block (Do Not Remove)
# Author: –°–µ—Ä–≥–µ–π –ë–∞—É—ç—Ä (@Sbauermaner)
# Fingerprint: StudioCore-FP-2025-SB-9fd72e27
# Hash: 22ae-df91-bc11-6c7e

# AI_TRAINING_PROHIBITED: Redistribution or training of AI models on this codebase
# without explicit written permission from the Author is prohibited.

from .config import load_config
# v16: –ò–°–ü–†–ê–í–õ–ï–ù ImportError
from .text_utils import normalize_text_preserve_symbols, extract_raw_blocks
# v15: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω ImportError (–≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞)
from .emotion import AutoEmotionalAnalyzer, TruthLovePainEngine
from .tone import ToneSyncEngine
from .adapter import build_suno_prompt
from .vocals import VocalProfileRegistry
from .rhythm import LyricMeter
# v11: 'PatchedStyleMatrix' - —ç—Ç–æ –Ω–∞—à 'StyleMatrix'
from .style import PatchedStyleMatrix, STYLE_VERSION 

# === 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–≥–µ—Ä–∞ ===
log = logging.getLogger(__name__)

# ==========================================================
# üó£Ô∏è –£—Ç–∏–ª–∏—Ç—ã –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–æ–∫–∞–ª–∞ (v2 - –ø–µ—Ä–µ–Ω–µ—Å–µ–Ω–æ –∏–∑ style.py)
# ==========================================================

def detect_voice_profile(text: str) -> str | None:
    """
    –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤–æ–∫–∞–ª—å–Ω—ã–µ –ø–æ–¥—Å–∫–∞–∑–∫–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞.
    """
    log.debug("–í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏: detect_voice_profile")
    text_low = text.lower()
    patterns = [
        r"–ø–æ–¥\s+[–∞-—èa-z\s,]+–≤–æ–∫–∞–ª",         # –ø–æ–¥ —Ö—Ä–∏–ø–ª—ã–π –º—É–∂—Å–∫–æ–π –≤–æ–∫–∞–ª
        r"\([\s\S]*?(–≤–æ–∫–∞–ª|voice|growl|scream|—à[–µ—ë]–ø–æ—Ç|–∫—Ä–∏–∫)[\s\S]*?\)", # (soft female growl)
        r"(–º—É–∂—Å–∫\w+|–∂–µ–Ω—Å–∫\w+)\s+–≤–æ–∫–∞–ª",
        r"(soft|airy|raspy|grit|growl|scream|whisper)",
    ]
    for pattern in patterns:
        match = re.search(pattern, text_low)
        if match:
            hint = match.group(0).strip("() ")
            log.debug(f"–û–ø–∏—Å–∞–Ω–∏–µ –≤–æ–∫–∞–ª–∞ –Ω–∞–π–¥–µ–Ω–æ: {hint}")
            return hint
            
    log.debug("–û–ø–∏—Å–∞–Ω–∏–µ –≤–æ–∫–∞–ª–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
    return None

def detect_gender_from_grammar(text: str) -> str | None:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–æ–ª –ø–æ –≥—Ä–∞–º–º–∞—Ç–∏–∫–µ ("—è —à–µ–ª" / "—è —à–ª–∞")
    """
    log.debug("–í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏: detect_gender_from_grammar")
    male_verbs = len(re.findall(r"\b(—è\s+\w+–ª)\b", text, re.I))
    female_verbs = len(re.findall(r"\b(—è\s+\w+–ª–∞)\b", text, re.I))
    log.debug(f"–ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑: Male —Ö–∏—Ç—ã={male_verbs}, Female —Ö–∏—Ç—ã={female_verbs}")

    if male_verbs > female_verbs:
        log.debug("–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞: male")
        return "male"
    if female_verbs > male_verbs:
        log.debug("–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞: female")
        return "female"
    if male_verbs > 0 and male_verbs == female_verbs:
        log.debug("–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞: mixed")
        return "mixed"
        
    log.debug("–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∞ (auto)")
    return "auto"


# ==========================================================
# üîπ –õ–æ–∫–∞–ª—å–Ω—ã–µ –ø–æ–¥—Å–∏—Å—Ç–µ–º—ã
# (–ú—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö, —á—Ç–æ–±—ã –Ω–µ –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å rhythm.py –∏ —Ç.–¥. –≤ —Ç–µ—Å—Ç–∞—Ö)
# ==========================================================

class PatchedLyricMeter:
    """–û–±—ë—Ä—Ç–∫–∞ –Ω–∞–¥ –Ω–æ–≤—ã–º LyricMeter –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏."""

    def __init__(self) -> None:
        self._engine = LyricMeter()

    def analyze(
        self,
        text: str,
        *,
        emotions: Dict[str, float] | None = None,
        cf: float | None = None,
        tlp: Dict[str, float] | None = None,
        header_bpm: float | None = None,
    ):
        log.debug("–í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏: PatchedLyricMeter.analyze")
        tlp = tlp or {}
        if cf is None:
            cf = tlp.get("conscious_frequency")
        return self._engine.analyze(
            text,
            emotions=emotions,
            cf=cf,
            tlp=tlp,
            header_bpm=header_bpm,
        )

    def bpm_from_density(
        self,
        text: str,
        emo: Dict[str, float] | None = None,
        cf: float | None = None,
        tlp: Dict[str, float] | None = None,
    ) -> int:
        log.debug("–í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏: PatchedLyricMeter.bpm_from_density")
        analysis = self.analyze(text, emotions=emo, cf=cf, tlp=tlp)
        bpm = int(round(analysis["global_bpm"]))
        log.debug(
            "–†–∞—Å—á–µ—Ç BPM (patched): resolved=%s, header=%s, estimated=%s",
            bpm,
            analysis.get("header_bpm"),
            analysis.get("estimated_bpm"),
        )
        return bpm

class PatchedUniversalFrequencyEngine:
    def resonance_profile(self, tlp: Dict[str, float]) -> Dict[str, Any]:
        cf = tlp.get("conscious_frequency", 0.0)
        if cf > 0.7: rec = [4, 5, 6, 7]
        elif cf > 0.3: rec = [2, 3, 4, 5]
        else: rec = [1, 2, 3, 4]
        return {"recommended_octaves": rec}

class PatchedRNSSafety:
    def __init__(self, cfg: Dict[str, Any]):
        self.cfg = cfg.get("safety", {"safe_octaves": [2, 3, 4, 5]})
    def clamp_octaves(self, octaves: List[int]) -> List[int]:
        safe = set(self.cfg.get("safe_octaves", [2, 3, 4, 5]))
        arr = [o for o in octaves if o in safe]
        return arr or [2, 3, 4]

class PatchedIntegrityScanEngine:
    def analyze(self, text: str) -> Dict[str, Any]:
        return {"status": "OK"} # –ó–∞–≥–ª—É—à–∫–∞

class AdaptiveVocalAllocator:
    def analyze(self, emo: Dict[str, float], tlp: Dict[str, float], bpm: int, text: str) -> Dict[str, Any]:
        # (–õ–æ–≥–∏–∫–∞ v2... –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
        return {"vocal_form": "auto", "gender": "auto", "vocal_count": 1}

# ==========================================================
# üöÄ StudioCore Monolith (v4.3.11)
# ==========================================================
class StudioCore:

    def __init__(self, config_path: str | None = None):
        log.debug("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è StudioCore...")
        self.cfg = load_config(config_path or "studio_config.json")
        
        log.debug("–ó–∞–≥—Ä—É–∑–∫–∞: AutoEmotionalAnalyzer")
        self.emotion = AutoEmotionalAnalyzer()
        log.debug("–ó–∞–≥—Ä—É–∑–∫–∞: TruthLovePainEngine")
        self.tlp = TruthLovePainEngine()
        
        log.debug("–ó–∞–≥—Ä—É–∑–∫–∞: PatchedLyricMeter")
        self.rhythm = PatchedLyricMeter()
        log.debug("–ó–∞–≥—Ä—É–∑–∫–∞: PatchedUniversalFrequencyEngine")
        self.freq = PatchedUniversalFrequencyEngine()
        log.debug("–ó–∞–≥—Ä—É–∑–∫–∞: PatchedRNSSafety")
        self.safety = PatchedRNSSafety(self.cfg)
        log.debug("–ó–∞–≥—Ä—É–∑–∫–∞: PatchedIntegrityScanEngine")
        self.integrity = PatchedIntegrityScanEngine()
        log.debug("–ó–∞–≥—Ä—É–∑–∫–∞: VocalProfileRegistry")
        self.vocals = VocalProfileRegistry()

        log.debug("–ó–∞–≥—Ä—É–∑–∫–∞: PatchedStyleMatrix")
        try:
            # (PatchedStyleMatrix - —ç—Ç–æ –Ω–∞—à StyleMatrix v11)
            self.style = PatchedStyleMatrix()
            log.info(f"üé® [StyleMatrix] –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–∞—Ç—á–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è (PatchedStyleMatrix).")
        except ImportError as e:
            log.error(f"–ù–ï –£–î–ê–õ–û–°–¨ –∑–∞–≥—Ä—É–∑–∏—Ç—å PatchedStyleMatrix: {e}")
            self.style = None # type: ignore

        log.debug("–ó–∞–≥—Ä—É–∑–∫–∞: ToneSyncEngine")
        self.tone = ToneSyncEngine()
        log.debug("–ó–∞–≥—Ä—É–∑–∫–∞: AdaptiveVocalAllocator")
        self.vocal_allocator = AdaptiveVocalAllocator()
        
        log.info(f"üîπ [StudioCore {STUDIOCORE_VERSION}] Monolith loaded (Section-Aware Duet Mode v2).")


    # -------------------------------------------------------
    # üé§ (v4) –ê–Ω–∞–ª–∏–∑ –≤–æ–∫–∞–ª–∞ –ø–æ —Å–µ–∫—Ü–∏—è–º
    # -------------------------------------------------------
    def _analyze_sections(self, text_blocks: List[str], ui_gender: str) -> Dict[str, Any]:
        """ 
        v4: –ü—Ä–æ–≥–æ–Ω—è–µ—Ç –∫–∞–∂–¥—ã–π –±–ª–æ–∫ —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ –≥—Ä–∞–º–º–∞—Ç–∏–∫—É –∏ —Ö–∏–Ω—Ç—ã,
        –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å –≤–æ–∫–∞–ª–∞.
        """
        log.debug("–í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏: _analyze_sections")
        
        section_profiles: List[Dict[str, str | None]] = []
        final_gender = "auto"
        user_voice_hint = None # –•–∏–Ω—Ç, –∑–∞–¥–∞–Ω–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º
        
        # 1. –ê–Ω–∞–ª–∏–∑ –∫–∞–∂–¥–æ–≥–æ –±–ª–æ–∫–∞
        for block_text in text_blocks:
            # 1a. –ò—â–µ–º –≥—Ä–∞–º–º–∞—Ç–∏–∫—É ("—è —à–µ–ª" / "—è –∂–¥–∞–ª–∞")
            g_gender = detect_gender_from_grammar(block_text)
            
            # 1b. –ò—â–µ–º —Ö–∏–Ω—Ç—ã ("(—à–µ–ø–æ—Ç–æ–º)", "(–º—É–∂—Å–∫–æ–π –≤–æ–∫–∞–ª)")
            v_hint = detect_voice_profile(block_text)
            
            if v_hint and not user_voice_hint:
                user_voice_hint = v_hint # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–≤—ã–π –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ö–∏–Ω—Ç
            
            section_profiles.append({
                "gender": g_gender,
                "hint": v_hint
            })
            # v5: –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∞ –æ—à–∏–±–∫–∞ f-string (—É–±—Ä–∞–Ω–æ —Ç—Ä–æ–µ—Ç–æ—á–∏–µ)
            log.debug(f"–ë–ª–æ–∫ [{block_text[:20]}...] -> –ü–æ–ª: {g_gender}, –•–∏–Ω—Ç: {v_hint}")


        # 2. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –ø–æ–ª–∞ (–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç—ã)
        genders_found = {p["gender"] for p in section_profiles if p["gender"]}
        
        if ui_gender != "auto":
            final_gender = ui_gender # 1. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç UI
            log.debug("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–ª –∏–∑ UI")
        elif "male" in genders_found and "female" in genders_found:
            final_gender = "mixed" # 2. –ì—Ä–∞–º–º–∞—Ç–∏—á–µ—Å–∫–∏–π –¥—É—ç—Ç
            log.debug("–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞ 'mixed' (M/F)")
        elif "male" in genders_found:
            final_gender = "male" # 3. –¢–æ–ª—å–∫–æ –º—É–∂—Å–∫–æ–π
            log.debug("–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞ 'male'")
        elif "female" in genders_found:
            final_gender = "female" # 4. –¢–æ–ª—å–∫–æ –∂–µ–Ω—Å–∫–∏–π
            log.debug("–ì—Ä–∞–º–º–∞—Ç–∏–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–∏–ª–∞ 'female'")
        # (else: –æ—Å—Ç–∞–µ—Ç—Å—è 'auto')
            
        log.debug(f"–ò—Ç–æ–≥ –ø–æ –≤–æ–∫–∞–ª—É (–≤—Å–µ –±–ª–æ–∫–∏): {genders_found}")
        return {
            "final_gender_preference": final_gender,
            "user_voice_hint": user_voice_hint,
            "section_profiles": section_profiles
        }

    # -------------------------------------------------------
    # üéº (v6) –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏—Ö —Å–µ–∫—Ü–∏–π
    # -------------------------------------------------------
    def _build_semantic_layers(self, emo: Dict[str,float], tlp: Dict[str,float], bpm: int, style_key: str) -> Dict[str, Any]:
        """ v6: –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç 'energy', 'arrangement' –∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç 'key' """
        log.debug("–í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏: _build_semantic_layers")
        
        love, pain, truth = tlp.get("love",0), tlp.get("pain",0), tlp.get("truth",0)
        cf = tlp.get("conscious_frequency",0)
        avg_emo = mean(abs(v) for v in emo.values()) if emo else 0.0
        
        key = style_key # –ë–µ—Ä–µ–º —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∏–∑ style.py

        def get_focus(mood: str, energy: str) -> str:
            if energy == "high": return "climax"
            if energy == "low": return "minimal"
            if mood == "dramatic": return "contrast"
            if mood == "narrative": return "story_flow"
            return "flow"

        # (v6) –õ–æ–≥–∏–∫–∞ –æ—Å–Ω–æ–≤–∞–Ω–∞ –Ω–∞ —à–∞–±–ª–æ–Ω–∞—Ö Suno
        intro = {
            "tag": "Intro", "mood": "mystic" if cf >= 0.5 else "calm", "energy": "low", 
            "arrangement": "minimal", "bpm": int(bpm*0.8), "key": key
        }
        verse = {
            "tag": "Verse", "mood": "narrative" if love >= truth else "reflective", "energy": "mid",
            "arrangement": "standard", "bpm": bpm, "key": key
        }
        bridge = {
            "tag": "Bridge", "mood": "dramatic" if pain > 0.3 else "dreamlike", "energy": "mid-high",
            "arrangement": "building", "bpm": int(bpm * 1.05), "key": key
        }
        chorus = {
            "tag": "Chorus", "mood": "uplifting" if love >= pain else "tense", "energy": "high",
            "arrangement": "full arrangement", "bpm": int(bpm * 1.1), "key": key
        }
        outro = {
            "tag": "Outro", "mood": "peaceful" if cf > 0.6 else "fading", "energy": "low",
            "arrangement": "minimal", "bpm": int(bpm*0.7), "key": key
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º 'focus' –Ω–∞ –æ—Å–Ω–æ–≤–µ mood/energy
        for s in [intro, verse, bridge, chorus, outro]:
            s["focus"] = get_focus(s["mood"], s["energy"])

        # v6: BPM —Ç–µ–ø–µ—Ä—å –∑–∞–≤–∏—Å–∏—Ç –æ—Ç TLP (–±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π —Ä–∞—Å—á–µ—Ç)
        bpm_adj = int(bpm + (love * 10) - (pain * 15) + (truth * 5))
        bpm_adj = max(60, min(180, bpm_adj))
        log.debug(f"BPM —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω –¥–æ {bpm_adj}")

        return {
            "bpm_suggested": bpm_adj,
            "layers": {
                "depth": round((truth + pain) / 2, 2),
                "warmth": round(love, 2),
                "clarity": round(cf, 2),
                "sections": [intro, verse, bridge, chorus, outro],
            },
        }

    # -------------------------------------------------------
    # ‚úçÔ∏è (v6) –ê–Ω–Ω–æ—Ç–∞—Ç–æ—Ä —Ç–µ–∫—Å—Ç–∞
    # -------------------------------------------------------
    def annotate_text(
        self, 
        text_blocks: List[str], 
        section_profiles: List[Dict[str, str | None]], 
        semantic_sections: List[Dict[str, Any]]
    ) -> Tuple[str, str]:
        """
        v6: –ü–æ–ª–Ω–æ—Å—Ç—å—é –ø–µ—Ä–µ–ø–∏—Å–∞–Ω. –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç 2 –≤–µ—Ä—Å–∏–∏:
        1.  `annotated_text_ui`: –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π (–¥–ª—è Gradio)
        2.  `annotated_text_suno`: –ß–∏—Å—Ç—ã–π (–¥–ª—è Suno Lyrics)
        """
        log.debug("–í—ã–∑–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏: annotate_text (v6)")
        
        ui_blocks = []
        suno_blocks = []
        
        num_blocks = len(text_blocks)
        
        # --- (v6) –£–ª—É—á—à–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –º—ç–ø–ø–∏–Ω–≥–∞ —Å–µ–∫—Ü–∏–π ---
        # intro, verse1, chorus1, verse2, chorus2, bridge, chorus3, outro
        semantic_map = []
        if num_blocks <= 5:
            semantic_map = ["Intro", "Verse", "Bridge", "Chorus", "Outro"]
        elif num_blocks == 6:
            semantic_map = ["Intro", "Verse", "Chorus", "Verse", "Chorus", "Outro"]
        elif num_blocks == 7:
            semantic_map = ["Intro", "Verse", "Pre-Chorus", "Chorus", "Verse", "Bridge", "Outro"]
        else: # 8+
            semantic_map = ["Intro", "Verse", "Pre-Chorus", "Chorus", "Verse", "Bridge", "Chorus", "Outro"]
            
        # –î–æ–ø–æ–ª–Ω—è–µ–º –∫–∞—Ä—Ç—É, –µ—Å–ª–∏ –±–ª–æ–∫–æ–≤ –±–æ–ª—å—à–µ 8
        if num_blocks > len(semantic_map):
            semantic_map.extend(["Verse", "Chorus"] * (num_blocks - len(semantic_map)))
        
        # –ù–∞—Ö–æ–¥–∏–º –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–µ–∫—Ü–∏–π
        sec_defs = {s["tag"].lower(): s for s in semantic_sections}
        # –ó–∞–ø–∞—Å–Ω—ã–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        sec_defs.setdefault("pre-chorus", sec_defs["bridge"])
        sec_defs.setdefault("verse 2", sec_defs["verse"])
        # --- –ö–æ–Ω–µ—Ü –ª–æ–≥–∏–∫–∏ –º—ç–ø–ø–∏–Ω–≥–∞ ---

        final_bpm = semantic_sections[0].get("bpm", 120) # (BPM –ø—Ä–∏–ø–µ–≤–∞)
        final_key = semantic_sections[0].get("key", "auto")
        final_vocal_form = "solo_auto" # –ë—É–¥–µ—Ç –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω

        for i, block_text in enumerate(text_blocks):
            if not block_text.strip():
                continue

            # 1. –ë–µ—Ä–µ–º —Å–µ–º–∞–Ω—Ç–∏–∫—É (Intro, Verse...)
            tag_name = semantic_map[i].lower()
            sem = sec_defs.get(tag_name, sec_defs["verse"]) # Fallback –Ω–∞ 'verse'
            
            # 2. –ë–µ—Ä–µ–º –≤–æ–∫–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å (Male, Female...)
            profile = section_profiles[i]
            gender_tag = profile.get("gender", "auto").upper() # MALE, FEMALE, MIXED, AUTO
            
            # 3. –°–æ–±–∏—Ä–∞–µ–º —Ç–µ–≥–∏
            suno_tag_parts = [
                tag_name.upper(),
                f"vocal: {gender_tag}" if gender_tag != "AUTO" else None,
                f"mood: {sem['mood']}",
                f"energy: {sem['energy']}",
                f"arrangement: {sem['arrangement']}",
            ]
            suno_tag = f"[{' - '.join(filter(None, suno_tag_parts))}]"
            
            # UI-—Ç–µ–≥ (–±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π)
            ui_tag = f"[{tag_name.upper()} - {gender_tag} - {sem['mood']}, {sem['energy']}, {sem['arrangement']}, BPM‚âà{sem['bpm']}]"
            
            # –û–±–Ω–æ–≤–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π BPM/Key (–±–µ—Ä–µ–º –∏–∑ –ø—Ä–∏–ø–µ–≤–∞, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å)
            if "chorus" in tag_name:
                final_bpm = sem['bpm']
                final_key = sem['key']

            ui_blocks.append(ui_tag)
            ui_blocks.append(block_text)
            ui_blocks.append("")
            
            suno_blocks.append(suno_tag)
            suno_blocks.append(block_text)
            suno_blocks.append("")

        # –§–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–≥
        # (vocal_form –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω –≤ 'analyze')
        end_tag_ui = f"[End ‚Äì BPM‚âà{final_bpm}, Tone={final_key}]"
        end_tag_suno = f"[{final_bpm} BPM, {final_key}]"
        
        ui_blocks.append(end_tag_ui)
        suno_blocks.append(end_tag_suno)

        return "\n".join(ui_blocks).strip(), "\n".join(suno_blocks).strip()


    # -------------------------------------------------------
    # üöÄ –ì–ª–∞–≤–Ω—ã–π –ü–∞–π–ø–ª–∞–π–Ω
    # -------------------------------------------------------
    def analyze(
        self,
        text: str,
        preferred_gender: str = "auto",
        version: Optional[str] = None,
        semantic_hints: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        
        log.debug(f"--- –ó–ê–ü–£–°–ö –ê–ù–ê–õ–ò–ó–ê (v{STUDIOCORE_VERSION}) ---")
        log.debug(f"Preferred Gender: {preferred_gender}, Text: {text[:40]}...")
        
        if not self.style:
            return {"error": "StyleMatrix –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω."}

        version = version or self.cfg.get("suno_version", "v5")
        
        # 1. –ë–∞–∑–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑
        log.debug("–í—ã–∑–æ–≤: normalize_text_preserve_symbols")
        raw = normalize_text_preserve_symbols(text)
        
        log.debug("–í—ã–∑–æ–≤: self.emotion.analyze")
        emo = self.emotion.analyze(raw)
        log.debug(f"–†–µ–∑—É–ª—å—Ç–∞—Ç EMO: {emo}")
        
        log.debug("–í—ã–∑–æ–≤: self.tlp.analyze")
        tlp = self.tlp.analyze(raw)
        log.debug(f"–†–µ–∑—É–ª—å—Ç–∞—Ç TLP: {tlp}")
        
        log.debug("–í—ã–∑–æ–≤: self.rhythm.analyze")
        rhythm_analysis = self.rhythm.analyze(
            raw,
            emotions=emo,
            tlp=tlp,
            cf=tlp.get("conscious_frequency"),
        )
        bpm_base = int(round(rhythm_analysis.get("global_bpm", 120)))
        log.debug(
            "–ë–∞–∑–æ–≤—ã–π BPM: %s (header=%s, estimated=%s)",
            bpm_base,
            rhythm_analysis.get("header_bpm"),
            rhythm_analysis.get("estimated_bpm"),
        )

        # 2. –ê–Ω–∞–ª–∏–∑ –≤–æ–∫–∞–ª–∞ –ø–æ —Å–µ–∫—Ü–∏—è–º
        log.debug("–í—ã–∑–æ–≤: self._analyze_sections")
        text_blocks = extract_raw_blocks(raw) # (–∏–∑ text_utils)
        vocal_analysis = self._analyze_sections(text_blocks, preferred_gender)
        
        final_gender_preference = vocal_analysis["final_gender_preference"]
        user_voice_hint = vocal_analysis["user_voice_hint"]
        
        log.debug(f"–°—Ç–∞—Ç—É—Å –≤–æ–∫–∞–ª—å–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞: {'USER-DEFINED' if user_voice_hint else 'AUTO-DETECT'}")

        # 3. –°—Ç–∏–ª—å (Style)
        log.debug("–í—ã–∑–æ–≤: self.style.build")
        # –ü–µ—Ä–µ–¥–∞–µ–º —Ö–∏–Ω—Ç –≤ style.build
        style = self.style.build(emo, tlp, raw, bpm_base, semantic_hints, user_voice_hint)
        log.debug(f"–†–µ–∑—É–ª—å—Ç–∞—Ç Style: Genre={style['genre']}, Style={style['style']}")

        # 4. –°–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–µ —Å–µ–∫—Ü–∏–∏ (Suno)
        # (–ò—Å–ø–æ–ª—å–∑—É–µ–º BPM –∏–∑ style.build –∏ –∫–ª—é—á –∏–∑ style.build)
        log.debug("–í—ã–∑–æ–≤: self._build_semantic_layers")
        semantic_layers = self._build_semantic_layers(emo, tlp, style.get('bpm', bpm_base), style.get('key'))
        bpm_adj = semantic_layers["bpm_suggested"]
        semantic_sections = semantic_layers["layers"]["sections"]
        
        # 5. –í–æ–∫–∞–ª –∏ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
        log.debug("–í—ã–∑–æ–≤: self.vocals.get")
        vox, inst, vocal_form = self.vocals.get(
            style["genre"],
            final_gender_preference,
            raw,
            [], # (sections –±–æ–ª—å—à–µ –Ω–µ –Ω—É–∂–Ω—ã, –∏—Å–ø–æ–ª—å–∑—É–µ–º vocal_profile_tags)
            vocal_analysis["section_profiles"]
        )
        style["vocal_form"] = vocal_form # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∏–ª—å —Ñ–∏–Ω–∞–ª—å–Ω–æ–π —Ñ–æ—Ä–º–æ–π
        style["vocal_count"] = vocal_analysis.get("vocal_count", 1) # (–∏–∑ allocator, –µ—Å–ª–∏ –æ–Ω –µ—Å—Ç—å)
        
        log.debug(f"–†–µ–∑—É–ª—å—Ç–∞—Ç Vocals: Form={vocal_form}, Vox={vox}, Inst={inst}, Count={style['vocal_count']}")

        # 6. –û—Å—Ç–∞–ª—å–Ω—ã–µ –¥–≤–∏–∂–∫–∏
        log.debug("–í—ã–∑–æ–≤: self.freq.resonance_profile")
        freq = self.freq.resonance_profile(tlp)
        freq["recommended_octaves"] = self.safety.clamp_octaves(freq["recommended_octaves"])
        
        log.debug("–í—ã–∑–æ–≤: self.integrity.analyze")
        integ = self.integrity.analyze(raw)
        
        log.debug("–í—ã–∑–æ–≤: self.tone.colors_for_primary")
        tone = self.tone.colors_for_primary(emo, tlp, style.get("key", "auto"))
        
        philosophy = (f"T={tlp.get('truth', 0):.2f}, L={tlp.get('love', 0):.2f}, "
                      f"P={tlp.get('pain', 0):.2f}, CF={tlp.get('conscious_frequency', 0):.2f}")

        # 7. –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è (v6 - Suno)
        log.debug("–í—ã–∑–æ–≤: self.annotate_text")
        annotated_text_ui, annotated_text_suno = self.annotate_text(
            text_blocks, 
            vocal_analysis["section_profiles"], 
            semantic_sections
        )

        # 8. –§–∏–Ω–∞–ª—å–Ω—ã–µ –ü—Ä–æ–º–ø—Ç—ã
        log.debug("–í—ã–∑–æ–≤: build_suno_prompt (STYLE)")
        prompt_suno_style = build_suno_prompt(style, vox, inst, bpm_adj, philosophy, version, prompt_variant="suno_style")

        log.debug("–í—ã–∑–æ–≤: build_suno_prompt (LYRICS)")
        prompt_suno_lyrics = build_suno_prompt(style, vox, inst, bpm_adj, philosophy, version, prompt_variant="suno_lyrics")

        log.debug("--- –ê–ù–ê–õ–ò–ó –£–°–ü–ï–®–ù–û –ó–ê–í–ï–†–®–ï–ù ---")

        return {
            "emotions": emo, "tlp": tlp, "bpm": bpm_adj, "frequency": freq,
            "style": style, "vocals": vox, "instruments": inst,
            "vocal_form": vocal_form, "final_gender_preference": final_gender_preference,
            "integrity": integ, "tone_sync": tone,
            "rhythm": rhythm_analysis,

            "annotated_text_ui": annotated_text_ui,     # v6: –î–ª—è Gradio UI
            "annotated_text_suno": annotated_text_suno, # v6: –î–ª—è Suno Lyrics
            "prompt_suno_style": prompt_suno_style,   # v6: –î–ª—è Suno Style
            "prompt_suno_lyrics": prompt_suno_lyrics, # v6: (Legacy)

            "semantic_layers": semantic_layers,
            "version": version,
            "vocal_detection_state": "AUTO-DETECT" if not user_voice_hint else "USER-DEFINED",
        }


class StudioCoreV5:
    """Compatibility wrapper exposing the v5 API expected by legacy tools."""

    def __init__(self, *args, **kwargs):
        self._core = StudioCore(*args, **kwargs)

    def analyze(self, *args, **kwargs):
        return self._core.analyze(*args, **kwargs)

    def emotion(self, text: str):
        return self._core.emotion.analyze(text)

    def style(
        self,
        emo: Dict[str, float],
        tlp: Dict[str, float],
        text: str,
        bpm: int,
        semantic_hints: Dict[str, Any] | None = None,
        voice_hint: str | None = None,
    ) -> Dict[str, Any]:
        if not self._core.style:
            raise RuntimeError("Style subsystem is unavailable.")
        return self._core.style.build(emo, tlp, text, bpm, semantic_hints, voice_hint)

    def tone(self, emo: Dict[str, float], tlp: Dict[str, float], key_hint: str | None = None):
        return self._core.tone.colors_for_primary(emo, tlp, key_hint or "auto")

    def rhythm(
        self,
        text: str,
        *,
        emotions: Dict[str, float] | None = None,
        tlp: Dict[str, float] | None = None,
        cf: float | None = None,
        header_bpm: float | None = None,
    ):
        return self._core.rhythm.analyze(
            text,
            emotions=emotions,
            tlp=tlp,
            cf=cf,
            header_bpm=header_bpm,
        )

    def __getattr__(self, item: str):
        return getattr(self._core, item)


# ==========================================================
STUDIOCORE_VERSION = "v4.3.11"
log.info(f"üîπ [StudioCore {STUDIOCORE_VERSION}] Monolith loaded (Section-Aware Duet Mode v2).")